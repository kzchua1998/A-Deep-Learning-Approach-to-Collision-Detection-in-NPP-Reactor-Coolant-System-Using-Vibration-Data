{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Activation, Conv2D,Conv1D, Flatten,MaxPooling2D,BatchNormalization,Lambda, AveragePooling2D, MaxPooling1D\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.layers import LSTM,Input,Bidirectional,Dense, Conv1D,MaxPooling1D,Flatten,Dropout,Input\n",
    "from tensorflow.keras.models import Model,Sequential\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X = pd.read_csv('dataset/train_features.csv')\n",
    "df_y = pd.read_csv('dataset/train_target.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_processing(data_frame,feature_list,conc_list=list()):\n",
    "    for feature in feature_list:\n",
    "        conc_list.append(np.asarray(data_frame[feature]).reshape(-1,375,1))\n",
    "    conc_array = np.concatenate(conc_list,axis=2)\n",
    "    array = conc_array.transpose(0,1,2)\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_processing(df_X,['S1','S2','S3','S4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_y.drop(['id','X','Y','V'],axis=1)\n",
    "y_numpy = y.to_numpy()\n",
    "y_list = y_numpy.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_array = data\n",
    "y_array = y_list\n",
    "train_test_index = int(len(x_array)*0.8)\n",
    "zip_list = list(zip(x_array,y_array))\n",
    "random.shuffle(zip_list)\n",
    "x_array,y_array = zip(*zip_list)\n",
    "x_train,y_train = np.array(x_array[0:train_test_index]),np.array(y_array[0:train_test_index])\n",
    "x_test,y_test = np.array(x_array[train_test_index:]),np.array(y_array[train_test_index:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.33333333],\n",
       "       [0.5       ],\n",
       "       [0.16666667],\n",
       "       ...,\n",
       "       [1.        ],\n",
       "       [0.83333333],\n",
       "       [0.83333333]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "Scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "y_train_scaled = Scaler.fit_transform(y_train)\n",
    "y_test_scaled = Scaler.fit_transform(y_test)\n",
    "y_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model= Sequential(\n",
    "    [\n",
    "        Input(shape=(x_train.shape[1],x_train.shape[2])),\n",
    "        # Use a Rescaling layer to make sure input values are in the [0, 1] range.\n",
    "        # The original images have shape (28, 28), so we reshape them to (28, 28, 1)\n",
    "        # Follow-up with a classic small convnet\n",
    "        Conv1D(32, 2, activation=\"relu\"),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling1D(3),\n",
    "        Conv1D(32,2, activation=\"relu\"),\n",
    "        MaxPooling1D(2),\n",
    "        Conv1D(32,2, activation=\"relu\"),\n",
    "        Flatten(),\n",
    "        Dense(64, activation=\"relu\"),\n",
    "        Dense(16, activation=\"relu\"),\n",
    "        Dense(1,activation='sigmoid')\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_loss(y_true, y_pred):\n",
    "    return K.mean(K.square(y_true-y_pred))/2e+04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=my_loss,optimizer='adam',metrics=['mean_absolute_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import callbacks\n",
    "early_stopping = callbacks.EarlyStopping(monitor =\"val_mean_absolute_error\", \n",
    "                                        mode =\"min\", patience = 50, \n",
    "                                        restore_best_weights = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "56/56 [==============================] - 7s 74ms/step - loss: 0.6131 - mean_absolute_error: 98.9964 - val_loss: 0.6450 - val_mean_absolute_error: 102.5714\n",
      "Epoch 2/500\n",
      "56/56 [==============================] - 1s 24ms/step - loss: 0.6171 - mean_absolute_error: 99.1067 - val_loss: 0.6450 - val_mean_absolute_error: 102.5714\n",
      "Epoch 3/500\n",
      "56/56 [==============================] - 1s 25ms/step - loss: 0.6048 - mean_absolute_error: 97.7907 - val_loss: 0.6450 - val_mean_absolute_error: 102.5714\n",
      "Epoch 4/500\n",
      "56/56 [==============================] - 1s 25ms/step - loss: 0.6027 - mean_absolute_error: 97.7474 - val_loss: 0.6450 - val_mean_absolute_error: 102.5714\n",
      "Epoch 5/500\n",
      "56/56 [==============================] - 1s 25ms/step - loss: 0.5960 - mean_absolute_error: 97.3446 - val_loss: 0.6450 - val_mean_absolute_error: 102.5714\n",
      "Epoch 6/500\n",
      "56/56 [==============================] - 1s 25ms/step - loss: 0.6107 - mean_absolute_error: 99.0014 - val_loss: 0.6450 - val_mean_absolute_error: 102.5714\n",
      "Epoch 7/500\n",
      "56/56 [==============================] - 1s 25ms/step - loss: 0.6005 - mean_absolute_error: 97.6264 - val_loss: 0.6450 - val_mean_absolute_error: 102.5714\n",
      "Epoch 8/500\n",
      "56/56 [==============================] - 1s 25ms/step - loss: 0.6101 - mean_absolute_error: 98.2117 - val_loss: 0.6450 - val_mean_absolute_error: 102.5714\n",
      "Epoch 9/500\n",
      "56/56 [==============================] - 1s 24ms/step - loss: 0.6038 - mean_absolute_error: 98.1675 - val_loss: 0.6450 - val_mean_absolute_error: 102.5714\n",
      "Epoch 10/500\n",
      "56/56 [==============================] - 1s 24ms/step - loss: 0.6099 - mean_absolute_error: 98.4371 - val_loss: 0.6450 - val_mean_absolute_error: 102.5714\n",
      "Epoch 11/500\n",
      "56/56 [==============================] - 1s 24ms/step - loss: 0.6022 - mean_absolute_error: 97.7899 - val_loss: 0.6450 - val_mean_absolute_error: 102.5714\n",
      "Epoch 12/500\n",
      "56/56 [==============================] - 1s 25ms/step - loss: 0.6089 - mean_absolute_error: 98.2753 - val_loss: 0.6450 - val_mean_absolute_error: 102.5714\n",
      "Epoch 13/500\n",
      "56/56 [==============================] - 1s 25ms/step - loss: 0.6203 - mean_absolute_error: 99.4548 - val_loss: 0.6450 - val_mean_absolute_error: 102.5714\n",
      "Epoch 14/500\n",
      "56/56 [==============================] - 1s 25ms/step - loss: 0.6068 - mean_absolute_error: 98.2250 - val_loss: 0.6450 - val_mean_absolute_error: 102.5714\n",
      "Epoch 15/500\n",
      "56/56 [==============================] - 1s 25ms/step - loss: 0.5713 - mean_absolute_error: 94.5813 - val_loss: 0.6450 - val_mean_absolute_error: 102.5714\n",
      "Epoch 16/500\n",
      "56/56 [==============================] - 1s 25ms/step - loss: 0.6179 - mean_absolute_error: 99.5352 - val_loss: 0.6450 - val_mean_absolute_error: 102.5714\n",
      "Epoch 17/500\n",
      "56/56 [==============================] - 1s 26ms/step - loss: 0.5744 - mean_absolute_error: 95.2949 - val_loss: 0.6450 - val_mean_absolute_error: 102.5714\n",
      "Epoch 18/500\n",
      "56/56 [==============================] - 1s 25ms/step - loss: 0.6041 - mean_absolute_error: 97.7717 - val_loss: 0.6450 - val_mean_absolute_error: 102.5714\n",
      "Epoch 19/500\n",
      "56/56 [==============================] - 1s 25ms/step - loss: 0.5953 - mean_absolute_error: 96.9352 - val_loss: 0.6450 - val_mean_absolute_error: 102.5714\n",
      "Epoch 20/500\n",
      "56/56 [==============================] - 1s 25ms/step - loss: 0.6110 - mean_absolute_error: 98.4393 - val_loss: 0.6450 - val_mean_absolute_error: 102.5714\n",
      "Epoch 21/500\n",
      "56/56 [==============================] - 1s 25ms/step - loss: 0.6179 - mean_absolute_error: 99.3525 - val_loss: 0.6450 - val_mean_absolute_error: 102.5714\n",
      "Epoch 22/500\n",
      "56/56 [==============================] - 1s 25ms/step - loss: 0.5972 - mean_absolute_error: 97.1259 - val_loss: 0.6450 - val_mean_absolute_error: 102.5714\n",
      "Epoch 23/500\n",
      "56/56 [==============================] - 1s 25ms/step - loss: 0.6170 - mean_absolute_error: 99.2034 - val_loss: 0.6450 - val_mean_absolute_error: 102.5714\n",
      "Epoch 24/500\n",
      "56/56 [==============================] - 1s 26ms/step - loss: 0.6184 - mean_absolute_error: 98.9806 - val_loss: 0.6450 - val_mean_absolute_error: 102.5714\n",
      "Epoch 25/500\n",
      "56/56 [==============================] - 1s 24ms/step - loss: 0.6078 - mean_absolute_error: 98.6090 - val_loss: 0.6450 - val_mean_absolute_error: 102.5714\n",
      "Epoch 26/500\n",
      "56/56 [==============================] - 1s 25ms/step - loss: 0.6197 - mean_absolute_error: 99.6249 - val_loss: 0.6450 - val_mean_absolute_error: 102.5714\n",
      "Epoch 27/500\n",
      "56/56 [==============================] - 1s 25ms/step - loss: 0.6132 - mean_absolute_error: 98.7167 - val_loss: 0.6450 - val_mean_absolute_error: 102.5714\n",
      "Epoch 28/500\n",
      "56/56 [==============================] - 1s 24ms/step - loss: 0.5840 - mean_absolute_error: 95.8744 - val_loss: 0.6450 - val_mean_absolute_error: 102.5714\n",
      "Epoch 29/500\n",
      "56/56 [==============================] - 1s 25ms/step - loss: 0.6014 - mean_absolute_error: 97.4272 - val_loss: 0.6450 - val_mean_absolute_error: 102.5714\n",
      "Epoch 30/500\n",
      "56/56 [==============================] - 1s 25ms/step - loss: 0.6021 - mean_absolute_error: 97.4829 - val_loss: 0.6450 - val_mean_absolute_error: 102.5714\n",
      "Epoch 31/500\n",
      "56/56 [==============================] - 1s 25ms/step - loss: 0.6002 - mean_absolute_error: 97.3553 - val_loss: 0.6450 - val_mean_absolute_error: 102.5714\n",
      "Epoch 32/500\n",
      "56/56 [==============================] - 1s 25ms/step - loss: 0.6068 - mean_absolute_error: 98.2595 - val_loss: 0.6450 - val_mean_absolute_error: 102.5714\n",
      "Epoch 33/500\n",
      "56/56 [==============================] - 1s 25ms/step - loss: 0.5862 - mean_absolute_error: 96.1664 - val_loss: 0.6450 - val_mean_absolute_error: 102.5714\n",
      "Epoch 34/500\n",
      "56/56 [==============================] - 1s 25ms/step - loss: 0.5870 - mean_absolute_error: 96.2363 - val_loss: 0.6450 - val_mean_absolute_error: 102.5714\n",
      "Epoch 35/500\n",
      "56/56 [==============================] - 1s 25ms/step - loss: 0.6155 - mean_absolute_error: 98.9091 - val_loss: 0.6450 - val_mean_absolute_error: 102.5714\n",
      "Epoch 36/500\n",
      "56/56 [==============================] - 1s 24ms/step - loss: 0.5873 - mean_absolute_error: 96.3212 - val_loss: 0.6450 - val_mean_absolute_error: 102.5714\n",
      "Epoch 37/500\n",
      "56/56 [==============================] - 1s 24ms/step - loss: 0.6086 - mean_absolute_error: 98.5128 - val_loss: 0.6450 - val_mean_absolute_error: 102.5714\n",
      "Epoch 38/500\n",
      "56/56 [==============================] - 1s 25ms/step - loss: 0.6154 - mean_absolute_error: 99.1379 - val_loss: 0.6450 - val_mean_absolute_error: 102.5714\n",
      "Epoch 39/500\n",
      "56/56 [==============================] - 1s 24ms/step - loss: 0.5981 - mean_absolute_error: 97.1030 - val_loss: 0.6450 - val_mean_absolute_error: 102.5714\n",
      "Epoch 40/500\n",
      "56/56 [==============================] - 1s 25ms/step - loss: 0.6226 - mean_absolute_error: 99.8276 - val_loss: 0.6450 - val_mean_absolute_error: 102.5714\n",
      "Epoch 41/500\n",
      "56/56 [==============================] - 1s 25ms/step - loss: 0.6156 - mean_absolute_error: 98.9888 - val_loss: 0.6450 - val_mean_absolute_error: 102.5714\n",
      "Epoch 42/500\n",
      "56/56 [==============================] - 1s 25ms/step - loss: 0.6010 - mean_absolute_error: 97.3239 - val_loss: 0.6450 - val_mean_absolute_error: 102.5714\n",
      "Epoch 43/500\n",
      "56/56 [==============================] - 1s 26ms/step - loss: 0.6247 - mean_absolute_error: 99.5842 - val_loss: 0.6450 - val_mean_absolute_error: 102.5714\n",
      "Epoch 44/500\n",
      "56/56 [==============================] - 1s 25ms/step - loss: 0.5942 - mean_absolute_error: 96.8937 - val_loss: 0.6450 - val_mean_absolute_error: 102.5714\n",
      "Epoch 45/500\n",
      "56/56 [==============================] - 1s 25ms/step - loss: 0.6169 - mean_absolute_error: 99.2008 - val_loss: 0.6450 - val_mean_absolute_error: 102.5714\n",
      "Epoch 46/500\n",
      "56/56 [==============================] - 1s 25ms/step - loss: 0.6199 - mean_absolute_error: 99.8114 - val_loss: 0.6450 - val_mean_absolute_error: 102.5714\n",
      "Epoch 47/500\n",
      "56/56 [==============================] - 1s 25ms/step - loss: 0.6081 - mean_absolute_error: 98.4733 - val_loss: 0.6450 - val_mean_absolute_error: 102.5714\n",
      "Epoch 48/500\n",
      "56/56 [==============================] - 1s 25ms/step - loss: 0.6291 - mean_absolute_error: 100.5752 - val_loss: 0.6450 - val_mean_absolute_error: 102.5714\n",
      "Epoch 49/500\n",
      "56/56 [==============================] - 1s 25ms/step - loss: 0.6146 - mean_absolute_error: 99.0237 - val_loss: 0.6450 - val_mean_absolute_error: 102.5714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/500\n",
      "56/56 [==============================] - 1s 24ms/step - loss: 0.5972 - mean_absolute_error: 97.0227 - val_loss: 0.6450 - val_mean_absolute_error: 102.5714\n",
      "Epoch 51/500\n",
      "56/56 [==============================] - 1s 24ms/step - loss: 0.6185 - mean_absolute_error: 99.1729 - val_loss: 0.6450 - val_mean_absolute_error: 102.5714\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train,y_train,validation_split=0.2,epochs=500,callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 4ms/step - loss: 1.9235e-08 - mean_absolute_error: 0.0120\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.9235152137753175e-08, 0.011954731307923794]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = model.predict(np.expand_dims(x_test[0],axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model/model_v.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
